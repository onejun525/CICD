
from fastapi import APIRouter, HTTPException, Depends, status
from openai import OpenAI
from dotenv import load_dotenv
from sqlalchemy.orm import Session
from datetime import datetime, timezone
import models
from routers.user_router import get_current_user
from database import SessionLocal
import os
import json

from schemas import (
    ChatbotRequest,
    ChatbotHistoryResponse,
    ChatItemModel,
    ChatResModel,
    ReportCreate,
    ReportResponse,
)
from routers.feedback_router import generate_ai_feedbacks
from utils.shared import top_k_chunks, build_rag_index, analyze_conversation_for_color_tone

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ëª¨ë¸ ì„¤ì •
EMOTION_MODEL_ID = os.getenv("EMOTION_MODEL_ID")
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "gpt-4.1-nano-2025-04-14")

client = OpenAI(api_key=OPENAI_API_KEY)
router = APIRouter(prefix="/api/chatbot", tags=["Chatbot"])


# ëª¨ë¸ ì„ íƒ í•¨ìˆ˜ (ì¤‘ë³µ ì œê±°)
def get_model_to_use():
    return EMOTION_MODEL_ID if EMOTION_MODEL_ID else DEFAULT_MODEL

# ëª¨ë¸ ìƒíƒœ ì¶œë ¥
print(f"ğŸš€ Chatbot Router ì´ˆê¸°í™”")
print(f"   - ê¸°ë³¸ ëª¨ë¸: {DEFAULT_MODEL}")
if EMOTION_MODEL_ID:
    print(f"   - Fine-tuned ê°ì • ëª¨ë¸: {EMOTION_MODEL_ID[:30]}***")
    print(f"   âœ… Fine-tuned ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
else:
    print(f"   âš ï¸ Fine-tuned ëª¨ë¸ ë¯¸ì„¤ì •, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")

def generate_complete_diagnosis_data(conversation_text: str, season: str) -> dict:
    """
    OpenAI APIë¥¼ í†µí•´ ì™„ì „í•œ ì§„ë‹¨ ë°ì´í„° ìƒì„±
    """
    try:
        # ëŒ€í™” í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
        if len(conversation_text) > 1000:
            conversation_text = conversation_text[:1000] + "...(ìƒëµ)"
        prompt = f"""
ì‚¬ìš©ìì™€ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì „ë¬¸ê°€ì˜ ëŒ€í™”:
{conversation_text}

ìœ„ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ {season} íƒ€ì… í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨ ê²°ê³¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš” (ë‹¤ë¥¸ ì„¤ëª… ì—†ì´):
{{
    "emotional_description": "ê°ì„±ì ì´ê³  ê¸ì •ì ì¸ í•œ ë¬¸ì¥ (ì˜ˆ: ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ìƒê¸° ë„˜ì¹˜ëŠ” {season} íƒ€ì…ì…ë‹ˆë‹¤!)",
    "color_palette": ["{season} íƒ€ì…ì— ì–´ìš¸ë¦¬ëŠ” 5ê°œì˜ HEX ìƒ‰ìƒ ì½”ë“œ"],
    "style_keywords": ["{season} íƒ€ì…ì˜ íŠ¹ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” 5ê°œ í‚¤ì›Œë“œ"],
    "makeup_tips": ["ì‹¤ìš©ì ì¸ ë©”ì´í¬ì—… íŒ 4ê°œ"],
    "detailed_analysis": "ëŒ€í™” ë‚´ìš©ì„ ë°˜ì˜í•œ ê°œì¸í™”ëœ ë¶„ì„ (2-3ë¬¸ë‹¨, êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ í¬í•¨)"
}}

ì£¼ì˜ì‚¬í•­:
- detailed_analysisëŠ” ë°˜ë³µì ì¸ ë‚´ìš© ì—†ì´ ê°œì¸í™”ëœ ë¶„ì„ìœ¼ë¡œ ì‘ì„±
- ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ê°œì¸ì  íŠ¹ì„±ì„ ë°˜ì˜
- ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ í¬í•¨
- í•œêµ­ì–´ë¡œ ì‘ì„±
"""
        # ëª¨ë¸ ì„ íƒ í•¨ìˆ˜ ì‚¬ìš©
        response = client.chat.completions.create(
            model=get_model_to_use(),
            messages=[{
                "role": "system",
                "content": "ë‹¹ì‹ ì€ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•˜ê³  ê°œì¸í™”ëœ ì§„ë‹¨ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
            }, {
                "role": "user", 
                "content": prompt
            }],
            max_tokens=1000,
            temperature=0.3
        )
        ai_response = response.choices[0].message.content.strip()
        try:
            import re
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                result = json.loads(json_str)
                if not result.get("detailed_analysis") or len(result.get("detailed_analysis", "")) < 50:
                    print("âš ï¸ AI ë¶„ì„ ê²°ê³¼ê°€ ë„ˆë¬´ ì§§ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
                    return get_default_diagnosis_data(season)
                return result
        except Exception as parse_error:
            print(f"âŒ AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
            print(f"AI ì‘ë‹µ: {ai_response[:200]}...")
        return get_default_diagnosis_data(season)
    except Exception as e:
        print(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return get_default_diagnosis_data(season)

def get_default_diagnosis_data(season: str) -> dict:
    """
    API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ ì§„ë‹¨ ë°ì´í„°
    """
    default_data = {
        "ë´„": {
            "emotional_description": "ìƒê¸° ë„˜ì¹˜ê³  í™”ì‚¬í•œ ë‹¹ì‹ ì€ ë´„ ì›œí†¤ íƒ€ì…ì…ë‹ˆë‹¤! ë°ê³  ë”°ëœ»í•œ ìƒ‰ìƒì´ ìì—°ìŠ¤ëŸ½ê²Œ ì–´ìš¸ë¦¬ëŠ” ë§¤ë ¥ì ì¸ ë¶„ì´ì—ìš”.",
            "color_palette": ["#FFB6C1", "#FFA07A", "#FFFF99", "#98FB98", "#87CEEB"],
            "style_keywords": ["ë°ì€", "í™”ì‚¬í•œ", "ìƒë™ê° ìˆëŠ”", "ë”°ëœ»í•œ", "ìì—°ìŠ¤ëŸ¬ìš´"],
            "makeup_tips": ["ì½”ë„ ê³„ì—´ ë¦½ìŠ¤í‹±ìœ¼ë¡œ ìƒê¸° ì—°ì¶œ", "í”¼ì¹˜ ë¸”ëŸ¬ì…”ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í™ì¡°", "ê³¨ë“œ ì•„ì´ì„€ë„ë¡œ ë”°ëœ»í•œ ëˆˆë§¤", "ë¸Œë¼ìš´ ë§ˆìŠ¤ì¹´ë¼ë¡œ ë¶€ë“œëŸ¬ìš´ ëˆˆë§¤"],
            "detailed_analysis": "ë´„ ì›œí†¤ íƒ€ì…ì¸ ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ë°ì€ ìƒ‰ìƒì´ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” íƒ€ì…ì…ë‹ˆë‹¤.\n\ní‰ì†Œ ë°ê³  ê²½ì¾Œí•œ ì¸ìƒì„ ì£¼ëŠ” ë‹¹ì‹ ì—ê²ŒëŠ” ì½”ë„, í”¼ì¹˜, ì•„ì´ë³´ë¦¬ ê³„ì—´ì˜ ìƒ‰ìƒì´ í”¼ë¶€í†¤ì„ ë”ìš± ìƒë™ê° ìˆê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤. ë©”ì´í¬ì—… ì‹œì—ëŠ” ë„ˆë¬´ ì§„í•˜ê±°ë‚˜ ì¿¨í†¤ ê³„ì—´ë³´ë‹¤ëŠ” ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ ëŠë‚Œì˜ ìƒ‰ìƒì„ ì„ íƒí•˜ì‹œë©´ ë”ìš± ë§¤ë ¥ì ì¸ ëª¨ìŠµì„ ì—°ì¶œí•  ìˆ˜ ìˆì–´ìš”.\n\níŒ¨ì…˜ì—ì„œë„ í™”ì´íŠ¸, í¬ë¦¼, ì½”ë„, ì—°ë‘ìƒ‰ ë“±ì„ í™œìš©í•˜ì‹œë©´ í™œê¸°ì°¬ ë‹¹ì‹ ì˜ ë§¤ë ¥ì„ í•œì¸µ ë” ë‹ë³´ì´ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        },
        "ì—¬ë¦„": {
            "emotional_description": "ì‹œì›í•˜ê³  ìš°ì•„í•œ ë‹¹ì‹ ì€ ì—¬ë¦„ ì¿¨í†¤ íƒ€ì…ì…ë‹ˆë‹¤! ë¶€ë“œëŸ½ê³  ì„¸ë ¨ëœ ìƒ‰ìƒì´ ë‹¹ì‹ ì˜ ìš°ì•„í•¨ì„ ë”ìš± ë¹›ë‚˜ê²Œ í•´ì¤ë‹ˆë‹¤.",
            "color_palette": ["#E6E6FA", "#B0C4DE", "#FFC0CB", "#DDA0DD", "#F0F8FF"],
            "style_keywords": ["ë¶€ë“œëŸ¬ìš´", "ìš°ì•„í•œ", "ì„¸ë ¨ëœ", "ì‹œì›í•œ", "íŒŒìŠ¤í…”"],
            "makeup_tips": ["ë¡œì¦ˆ í•‘í¬ ë¦½ìœ¼ë¡œ ìƒì¾Œí•œ ì¸ìƒ", "ë¼ë²¤ë” ì•„ì´ì„€ë„ë¡œ ëª½í™˜ì  ëˆˆë§¤", "ì‹¤ë²„ í•˜ì´ë¼ì´í„°ë¡œ íˆ¬ëª…í•œ ìœ¤ê¸°", "ì• ì‰¬ ë¸Œë¼ìš´ ì•„ì´ë¸Œë¡œìš°ë¡œ ë¶€ë“œëŸ¬ìš´ ì¸ìƒ"],
            "detailed_analysis": "ì—¬ë¦„ ì¿¨í†¤ íƒ€ì…ì¸ ë‹¹ì‹ ì€ ì°¨ê°€ìš´ ê³„ì—´ì˜ ë¶€ë“œëŸ¬ìš´ ìƒ‰ìƒì´ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ìš°ì•„í•œ íƒ€ì…ì…ë‹ˆë‹¤.\n\në‹¹ì‹ ì˜ í”¼ë¶€í†¤ì—ëŠ” ë¡œì¦ˆ, ë¼ë²¤ë”, ë¯¼íŠ¸, ìŠ¤ì¹´ì´ë¸”ë£¨ ë“±ì˜ íŒŒìŠ¤í…” ê³„ì—´ ìƒ‰ìƒì´ ì™„ë²½í•˜ê²Œ ì¡°í™”ë¥¼ ì´ë£¹ë‹ˆë‹¤. ë©”ì´í¬ì—… ì‹œì—ëŠ” ë„ˆë¬´ ê°•ë ¬í•˜ê±°ë‚˜ ë”°ëœ»í•œ í†¤ë³´ë‹¤ëŠ” ì¿¨í•˜ê³  ë¶€ë“œëŸ¬ìš´ ìƒ‰ìƒì„ ì„ íƒí•˜ì‹œë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì„¸ë ¨ëœ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•  ìˆ˜ ìˆì–´ìš”.\n\nì˜ìƒ ì„ íƒ ì‹œì—ë„ í™”ì´íŠ¸, ì‹¤ë²„, ë„¤ì´ë¹„, ê·¸ë ˆì´ ê³„ì—´ì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ì—¬ í¬ì¸íŠ¸ ìƒ‰ìƒìœ¼ë¡œ íŒŒìŠ¤í…” í†¤ì„ í™œìš©í•˜ì‹œë©´ ìš°ì•„í•˜ë©´ì„œë„ í˜„ëŒ€ì ì¸ ë§¤ë ¥ì„ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        },
        "ê°€ì„": {
            "emotional_description": "ê¹Šì´ ìˆê³  ì„¸ë ¨ëœ ë‹¹ì‹ ì€ ê°€ì„ ì›œí†¤ íƒ€ì…ì…ë‹ˆë‹¤! ì§„í•˜ê³  ë”°ëœ»í•œ ìƒ‰ìƒì´ ë‹¹ì‹ ì˜ ì„±ìˆ™í•œ ë§¤ë ¥ì„ ì™„ë²½í•˜ê²Œ í‘œí˜„í•´ì¤ë‹ˆë‹¤.",
            "color_palette": ["#D2691E", "#CD853F", "#DEB887", "#BC8F8F", "#F4A460"],
            "style_keywords": ["ê¹Šì€", "ì„¸ë ¨ëœ", "ë”°ëœ»í•œ", "ì„±ìˆ™í•œ", "í´ë˜ì‹"],
            "makeup_tips": ["ë¸Œë¼ìš´ ê³„ì—´ ë¦½ìœ¼ë¡œ ì§€ì ì¸ ì¸ìƒ", "ê³¨ë“œ ë¸Œë¡ ì¦ˆ ì•„ì´ì„€ë„ë¡œ ê¹Šì€ ëˆˆë§¤", "ë”°ëœ»í•œ ì˜¤ë Œì§€ ë¸”ëŸ¬ì…”", "ë‹¤í¬ ë¸Œë¼ìš´ ë§ˆìŠ¤ì¹´ë¼ë¡œ ê°•ì¡°ëœ ì†ëˆˆì¹"],
            "detailed_analysis": "ê°€ì„ ì›œí†¤ íƒ€ì…ì¸ ë‹¹ì‹ ì€ ê¹Šì´ ìˆê³  í’ë¶€í•œ ìƒ‰ìƒì´ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ì„±ìˆ™í•˜ê³  ì„¸ë ¨ëœ íƒ€ì…ì…ë‹ˆë‹¤.\n\në‹¹ì‹ ì˜ í”¼ë¶€í†¤ì—ëŠ” ë¨¸ìŠ¤íƒ€ë“œ, ë¸Œë¦­, ì˜¬ë¦¬ë¸Œ, ë²„ê±´ë”” ë“±ì˜ ê¹Šê³  ë”°ëœ»í•œ ìƒ‰ìƒë“¤ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì¡°í™”ë¥¼ ì´ë£¹ë‹ˆë‹¤. ë©”ì´í¬ì—…ì—ì„œëŠ” ë² ì´ì§€, ë¸Œë¼ìš´, ê³¨ë“œ ê³„ì—´ì„ í™œìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš°ë©´ì„œë„ ì„¸ë ¨ëœ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•  ìˆ˜ ìˆì–´ìš”.\n\níŒ¨ì…˜ì—ì„œëŠ” ì¹´ë©œ, ë² ì´ì§€, ë¸Œë¼ìš´, ì™€ì¸ ì»¬ëŸ¬ ë“±ì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ì—¬ í¬ì¸íŠ¸ ìƒ‰ìƒìœ¼ë¡œ ë¨¸ìŠ¤íƒ€ë“œë‚˜ ì˜¬ë¦¬ë¸Œ ê·¸ë¦°ì„ í™œìš©í•˜ì‹œë©´ í´ë˜ì‹í•˜ë©´ì„œë„ íŠ¸ë Œë””í•œ ìŠ¤íƒ€ì¼ì„ ì™„ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        },
        "ê²¨ìš¸": {
            "emotional_description": "ëª…í™•í•˜ê³  ê°•ë ¬í•œ ë‹¹ì‹ ì€ ê²¨ìš¸ ì¿¨í†¤ íƒ€ì…ì…ë‹ˆë‹¤! ì„ ëª…í•˜ê³  ë“œë¼ë§ˆí‹±í•œ ìƒ‰ìƒì´ ë‹¹ì‹ ì˜ ì¹´ë¦¬ìŠ¤ë§ˆë¥¼ í•œì¸µ ë” ë‹ë³´ì´ê²Œ í•©ë‹ˆë‹¤.",
            "color_palette": ["#FF1493", "#4169E1", "#000000", "#FFFFFF", "#8A2BE2"],
            "style_keywords": ["ëª…í™•í•œ", "ê°•ë ¬í•œ", "ì„ ëª…í•œ", "ë“œë¼ë§ˆí‹±", "ëª¨ë˜"],
            "makeup_tips": ["ë ˆë“œ ë¦½ìŠ¤í‹±ìœ¼ë¡œ ê°•ë ¬í•œ í¬ì¸íŠ¸", "ì‹¤ë²„ ì•„ì´ì„€ë„ë¡œ ì‹ ë¹„ë¡œìš´ ëˆˆë§¤", "ë¸”ë™ ì•„ì´ë¼ì´ë„ˆë¡œ ë˜ë ·í•œ ëˆˆë§¤", "ë³¼ë“œí•œ ì»¨íˆ¬ì–´ë§ìœ¼ë¡œ ì…ì²´ê°"],
            "detailed_analysis": "ê²¨ìš¸ ì¿¨í†¤ íƒ€ì…ì¸ ë‹¹ì‹ ì€ ì„ ëª…í•˜ê³  ê°•ë ¬í•œ ìƒ‰ìƒì´ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ë“œë¼ë§ˆí‹±í•˜ê³  ëª¨ë˜í•œ íƒ€ì…ì…ë‹ˆë‹¤.\n\në‹¹ì‹ ì˜ í”¼ë¶€í†¤ì—ëŠ” í“¨ì–´ í™”ì´íŠ¸, ë¸”ë™, ë¡œì–„ ë¸”ë£¨, ì—ë©”ë„ë“œ ê·¸ë¦° ë“±ì˜ ì„ ëª…í•˜ê³  ì°¨ê°€ìš´ ìƒ‰ìƒë“¤ì´ ì™„ë²½í•˜ê²Œ ì–´ìš¸ë¦½ë‹ˆë‹¤. ë©”ì´í¬ì—…ì—ì„œëŠ” ëª…í™•í•œ ì»¬ëŸ¬ ëŒ€ë¹„ë¥¼ í™œìš©í•˜ì—¬ ì‹œí¬í•˜ê³  ì„¸ë ¨ëœ ì´ë¯¸ì§€ë¥¼ ì—°ì¶œí•  ìˆ˜ ìˆì–´ìš”.\n\nì˜ìƒ ì„ íƒ ì‹œì—ë„ ë¸”ë™, í™”ì´íŠ¸, ê·¸ë ˆì´ë¥¼ ë² ì´ìŠ¤ë¡œ í•˜ì—¬ í¬ì¸íŠ¸ ìƒ‰ìƒìœ¼ë¡œ ë¹„ë¹„ë“œí•œ ì»¬ëŸ¬ë¥¼ í™œìš©í•˜ì‹œë©´ ë‹¹ì‹ ë§Œì˜ ë…íŠ¹í•˜ê³  ê°•ì¸í•œ ë§¤ë ¥ì„ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }
    }
    
    return default_data.get(season, default_data["ë´„"])

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# RAG ì¸ë±ìŠ¤ êµ¬ì¶• (ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰)
fixed_index = build_rag_index(client, "data/RAG/personal_color_RAG.txt")
trend_index = build_rag_index(client, "data/RAG/beauty_trend_2025_autumn_RAG.txt")

def clean_analysis_text(text: str) -> str:
    """
    ë¶„ì„ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
    """
    if not text:
        return ""
    
    # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    text = text.strip()
    
    # ì—°ì†ëœ ì¤„ë°”ê¿ˆì„ í•˜ë‚˜ë¡œ ì •ë¦¬
    import re
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
    
    # ì¤‘ë³µëœ ë¬¸ì¥ ì œê±° (ê°„ë‹¨í•œ ì¤‘ë³µ ì²´í¬)
    sentences = text.split('. ')
    unique_sentences = []
    seen = set()
    
    for sentence in sentences:
        sentence = sentence.strip()
        if sentence and sentence not in seen and len(sentence) > 10:
            seen.add(sentence)
            unique_sentences.append(sentence)
    
    return '. '.join(unique_sentences) if unique_sentences else text

async def save_chatbot_analysis_result(
    user_id: int,
    chat_history_id: int,
    db: Session,
    force: bool = False,
):
    """
    ğŸ†• ìƒˆë¡œìš´ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨ ê¸°ë¡ ìƒì„± ğŸ†•
    
    âš ï¸ ì¤‘ìš”: ì´ í•¨ìˆ˜ëŠ” ìƒˆë¡œìš´ ì§„ë‹¨ ê¸°ë¡(SurveyResult)ì„ ìƒì„±í•©ë‹ˆë‹¤!
    - ì±—ë´‡ ëŒ€í™” ë¶„ì„ì„ í†µí•œ ìƒˆë¡œìš´ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨
    - ë§ˆì´í˜ì´ì§€ ì§„ë‹¨ ê¸°ë¡ì— ìƒˆë¡œìš´ í•­ëª©ì´ ì¶”ê°€ë¨
    - ëŒ€í™” ë‚´ìš©ì„ AIê°€ ë¶„ì„í•˜ì—¬ ìƒˆë¡œìš´ ì§„ë‹¨ ê²°ê³¼ ë„ì¶œ
    
    í˜¸ì¶œ ì‹œì :
    1. ëŒ€í™” ì„¸ì…˜ ì¢…ë£Œ ì‹œ (ì¶©ë¶„í•œ ëŒ€í™”ê°€ ì§„í–‰ëœ ê²½ìš°)
    """
    try:
        # ğŸ” ì¤‘ë³µ ë°©ì§€: force=Trueì´ë©´ ì¤‘ë³µ ì²´í¬ë¥¼ ë¬´ì‹œí•˜ê³  í•­ìƒ ìƒˆ ë ˆì½”ë“œ ìƒì„±
        if not force:
            existing_result = db.query(models.SurveyResult).filter(
                models.SurveyResult.user_id == user_id,
                models.SurveyResult.source_type == "chatbot",
                models.SurveyResult.is_active == True
            ).order_by(models.SurveyResult.created_at.desc()).first()

            # ìµœê·¼ ìƒì„±ëœ ì§„ë‹¨ ê²°ê³¼ê°€ 5ë¶„ ì´ë‚´ë¼ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
            if existing_result:
                from datetime import timedelta
                # DBì— ì €ì¥ëœ created_atì´ tz-naiveì¸ ê²½ìš°ê°€ ìˆì–´ subtraction ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìŒ
                existing_created_at = existing_result.created_at
                if existing_created_at is None:
                    # ì•ˆì „í•˜ê²Œ ë„˜ì–´ê°
                    existing_created_at = datetime.now(timezone.utc)
                # if DB returned a naive datetime (no tzinfo), assume UTC
                if existing_created_at.tzinfo is None:
                    existing_created_at = existing_created_at.replace(tzinfo=timezone.utc)

                time_diff = datetime.now(timezone.utc) - existing_created_at
                if time_diff < timedelta(minutes=5):
                    print(f"ğŸ”„ ì¤‘ë³µ ì§„ë‹¨ ë°©ì§€: ìµœê·¼ {time_diff.seconds}ì´ˆ ì „ì— ìƒì„±ëœ ê²°ê³¼ ì¬ì‚¬ìš©")
                    print(f"   - ê¸°ì¡´ ê²°ê³¼ ID: {existing_result.id}")
                    print(f"   - ê¸°ì¡´ ê²°ê³¼ íƒ€ì…: {existing_result.result_tone}")
                    return existing_result
        print(f"ğŸ” ìƒˆë¡œìš´ ì§„ë‹¨ ê¸°ë¡ ìƒì„± ì‹œì‘: user_id={user_id}, chat_history_id={chat_history_id}")
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì—ì„œ ë©”ì‹œì§€ë“¤ ê°€ì ¸ì˜¤ê¸°
        messages = db.query(models.ChatMessage).filter_by(
            history_id=chat_history_id
        ).order_by(models.ChatMessage.created_at.asc()).all()
        
        if not messages:
            print("âŒ ëŒ€í™” ë©”ì‹œì§€ê°€ ì—†ì–´ì„œ ì§„ë‹¨ ë¶ˆê°€")
            return None
            
        print(f"ğŸ“ ëŒ€í™” ë©”ì‹œì§€ {len(messages)}ê°œ ë°œê²¬, ë¶„ì„ ì‹œì‘...")
        
        # ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í¼ìŠ¤ë„ ì»¬ëŸ¬ ê²°ì •
        conversation_text = ""
        for msg in messages:
            if msg.role == "user":
                conversation_text += f"User: {msg.text}\n"
            elif msg.role == "ai":
                try:
                    ai_data = json.loads(msg.text)
                    conversation_text += f"AI: {ai_data.get('description', msg.text)}\n"
                except:
                    conversation_text += f"AI: {msg.text}\n"
        
        # ëŒ€í™” ë¶„ì„ì„ í†µí•œ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨
        primary_tone, sub_tone = analyze_conversation_for_color_tone(
            conversation_text, ""  # í˜„ì¬ ì§ˆë¬¸ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬ (ì „ì²´ ëŒ€í™” ê¸°ë°˜ ë¶„ì„)
        )
        
        print(f"ğŸ¨ AI ë¶„ì„ ê²°ê³¼: {primary_tone}í†¤ {sub_tone}")
        
        # ğŸ†• OpenAIë¥¼ í†µí•œ ì™„ì „í•œ ì§„ë‹¨ ë°ì´í„° ìƒì„±
        print("ğŸ¤– OpenAI APIë¥¼ í†µí•œ ë§ì¶¤í˜• ì§„ë‹¨ ë°ì´í„° ìƒì„± ì¤‘...")
        ai_diagnosis_data = generate_complete_diagnosis_data(conversation_text, sub_tone)
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        cleaned_analysis = clean_analysis_text(ai_diagnosis_data["detailed_analysis"])
        
        # ê¸°ë³¸ íƒ€ì… ì •ë³´ì— AI ìƒì„± ë°ì´í„° ì ìš©
        type_info = {
            "name": f"{sub_tone} {primary_tone}í†¤",
            "description": ai_diagnosis_data["emotional_description"],
            "detailed_analysis": cleaned_analysis,
            "color_palette": ai_diagnosis_data["color_palette"],
            "style_keywords": ai_diagnosis_data["style_keywords"],
            "makeup_tips": ai_diagnosis_data["makeup_tips"]
        }
        
        # ê²°ê³¼ í†¤ ë° ì‹ ë¢°ë„ ì„¤ì •  
        result_tone = f"{primary_tone}í†¤ {sub_tone}"
        confidence = 0.85  # ê¸°ë³¸ ì‹ ë¢°ë„
        
        # primary_type ë§¤í•‘
        type_mapping = {
            ("ì›œ", "ë´„"): "spring",
            ("ì›œ", "ê°€ì„"): "autumn", 
            ("ì¿¨", "ì—¬ë¦„"): "summer",
            ("ì¿¨", "ê²¨ìš¸"): "winter"
        }
        primary_type = type_mapping.get((primary_tone, sub_tone), "spring")
        
        # Top types ìƒì„± (AI ìƒì„± ë°ì´í„° ê¸°ë°˜)
        top_types = [
            {
                "type": primary_type,
                "name": f"{sub_tone} {primary_tone}í†¤",
                "description": type_info["description"],
                "color_palette": type_info["color_palette"],
                "style_keywords": type_info["style_keywords"],
                "makeup_tips": type_info["makeup_tips"],
                "score": int(confidence * 100)
            }
        ]
        
        # SurveyResultë¡œ ìƒˆë¡œìš´ ì§„ë‹¨ ê¸°ë¡ ì €ì¥
        print(f"ğŸ’¾ ìƒˆë¡œìš´ ì§„ë‹¨ ê¸°ë¡ DB ì €ì¥ ì‹œì‘...")
        survey_result = models.SurveyResult(
            user_id=user_id,
            result_tone=primary_type,
            confidence=confidence,
            total_score=int(confidence * 100),
            source_type="chatbot",  # ì±—ë´‡ ë¶„ì„ ì¶œì²˜ í‘œì‹œ
            detailed_analysis=type_info["detailed_analysis"],
            result_name=type_info["name"],
            result_description=type_info["description"],
            color_palette=json.dumps(type_info["color_palette"], ensure_ascii=False),
            style_keywords=json.dumps(type_info["style_keywords"], ensure_ascii=False),
            makeup_tips=json.dumps(type_info["makeup_tips"], ensure_ascii=False),
            top_types=json.dumps(top_types, ensure_ascii=False)
        )
        
        db.add(survey_result)
        db.commit()
        db.refresh(survey_result)
        
        print(f"âœ… ìƒˆë¡œìš´ ì§„ë‹¨ ê¸°ë¡ ìƒì„± ì™„ë£Œ: survey_result_id={survey_result.id}")
        print(f"   - ì§„ë‹¨ íƒ€ì…: {survey_result.result_tone}")
        print(f"   - ì‹ ë¢°ë„: {survey_result.confidence}")
        print(f"   âš ï¸ ë§ˆì´í˜ì´ì§€ ì§„ë‹¨ ê¸°ë¡ì— ìƒˆë¡œìš´ í•­ëª© ì¶”ê°€ë¨")
        
        return survey_result
        
    except Exception as e:
        print(f"âŒ ì±—ë´‡ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        db.rollback()
        return None


@router.post("/report/save", response_model=ReportResponse)
async def save_report_now(
    request: ReportCreate,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ 3í„´ë§ˆë‹¤ í˜¸ì¶œí•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.
    force=Trueë¡œ `save_chatbot_analysis_result`ë¥¼ í˜¸ì¶œí•´ í•­ìƒ ìƒˆ ì§„ë‹¨ ê¸°ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not request.history_id:
        raise HTTPException(status_code=400, detail="history_idê°€ í•„ìš”í•©ë‹ˆë‹¤")

    survey_result = await save_chatbot_analysis_result(
        user_id=current_user.id,
        chat_history_id=request.history_id,
        db=db,
        force=request.force or True,  # ê¸°ë³¸ ë™ì‘ì€ ê°•ì œ ìƒì„±
    )

    if survey_result:
        # ìƒì„±ëœ survey_resultì˜ ìš”ì•½/ë¯¸ë¦¬ë³´ê¸° ë°ì´í„°ë¥¼ ìƒì„±
        try:
            from utils.report_generator import PersonalColorReportGenerator

            report_generator = PersonalColorReportGenerator()

            # survey_resultì— ì €ì¥ëœ JSON í•„ë“œ íŒŒì‹±
            def parse_json_field(val):
                if not val:
                    return []
                if isinstance(val, str):
                    try:
                        return json.loads(val)
                    except:
                        return []
                return val

            survey_data = {
                "result_tone": survey_result.result_tone,
                "result_name": survey_result.result_name,
                "confidence": survey_result.confidence,
                "detailed_analysis": survey_result.detailed_analysis,
                "color_palette": parse_json_field(survey_result.color_palette),
                "style_keywords": parse_json_field(survey_result.style_keywords),
                "makeup_tips": parse_json_field(survey_result.makeup_tips),
            }

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
            chat_history = []
            try:
                messages = db.query(models.ChatMessage).filter_by(
                    history_id=request.history_id
                ).order_by(models.ChatMessage.created_at.asc()).all()
                chat_history = [
                    {"role": msg.role, "text": msg.text, "created_at": msg.created_at.isoformat()}
                    for msg in messages
                ]
            except Exception:
                chat_history = []

            report_data = report_generator.generate_report_data(survey_data, chat_history)

        except Exception as e:
            print(f"âš ï¸ ë¦¬í¬íŠ¸ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            report_data = None

        # í”„ë¡ íŠ¸ê°€ ì¦‰ì‹œ í‘œì‹œí•˜ê¸° ì‰¬ìš´ ë¯¸ë¦¬ë³´ê¸° í•„ë“œë„ í•¨ê»˜ ë°˜í™˜
        return ReportResponse(
            survey_result_id=survey_result.id,
            message="ì§„ë‹¨ ê¸°ë¡ ìƒì„± ì™„ë£Œ",
            created_at=survey_result.created_at,
            result_tone=survey_result.result_tone,
            result_name=survey_result.result_name,
            detailed_analysis=survey_result.detailed_analysis,
            color_palette=(json.loads(survey_result.color_palette) if survey_result.color_palette else []),
            style_keywords=(json.loads(survey_result.style_keywords) if survey_result.style_keywords else []),
            makeup_tips=(json.loads(survey_result.makeup_tips) if survey_result.makeup_tips else []),
            report_data=report_data,
        )
    else:
        raise HTTPException(status_code=500, detail="ì§„ë‹¨ ê¸°ë¡ ìƒì„± ì‹¤íŒ¨")

def detect_emotion(text: str) -> str:
    """
    OpenAI ê¸°ë°˜ ê°ì • ë¶„ì„ (Lottie emotion string ë°˜í™˜)
    """
    prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ì ë°œí™”ì˜ ê°ì •ì„ ë¶„ë¥˜í•˜ì„¸ìš”. ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•˜ì„¸ìš”:
smile, sad, angry, love, no, wink
ë°œí™”: "{text}"
ê°ì • (ìœ„ ëª©ë¡ ì¤‘ í•˜ë‚˜):
"""
    try:
        response = client.chat.completions.create(
            model=get_model_to_use(),
            messages=[{"role": "system", "content": "ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ì ë°œí™”ì˜ ê°ì •ì„ ë¶„ë¥˜í•´ì¤˜."},
                      {"role": "user", "content": prompt}],
            max_tokens=10,
            temperature=0.0
        )
        emotion = response.choices[0].message.content.strip().lower()
        # Lottie emotion mapping
        valid_emotions = ["smile", "sad", "angry", "love", "no", "wink"]
        for e in valid_emotions:
            if e in emotion:
                return e
        return "wink"
    except Exception as e:
        print(f"[detect_emotion] OpenAI ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
        return "wink"

@router.post("/analyze", response_model=ChatbotHistoryResponse)
def analyze(
    request: ChatbotRequest,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # ì‹ ê·œ ì„¸ì…˜ ìƒì„± ë˜ëŠ” ê¸°ì¡´ ì„¸ì…˜ ì´ì–´ë°›ê¸°
    if not request.history_id:
        chat_history = models.ChatHistory(user_id=current_user.id)
        db.add(chat_history)
        db.commit()
        db.refresh(chat_history)
    else:
        chat_history = db.query(models.ChatHistory).filter_by(id=request.history_id, user_id=current_user.id).first()
        if not chat_history:
            raise HTTPException(status_code=404, detail="í•´ë‹¹ history_id ì„¸ì…˜ ì—†ìŒ")
        if chat_history.ended_at:
            raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¢…ë£Œëœ ì„¸ì…˜ì…ë‹ˆë‹¤.")
    user_msg = models.ChatMessage(history_id=chat_history.id, role="user", text=request.question)
    db.add(user_msg)
    db.commit()
    db.refresh(user_msg)
    # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ì—ì„œ ì‚¬ìš©ì ì •ë³´ ìˆ˜ì§‘
    prev_messages = db.query(models.ChatMessage).filter_by(history_id=chat_history.id).order_by(models.ChatMessage.id.asc()).all()
    # ë‹‰ë„¤ì„ ì‚¬ìš©: current_user.nicknameì´ ìˆìœ¼ë©´, ì—†ìœ¼ë©´ 'ì‚¬ìš©ì'
    user_display_name = getattr(current_user, "nickname", None)
    if not user_display_name:
        user_display_name = "ì‚¬ìš©ì"
    conversation_history = ""
    user_characteristics = []
    if prev_messages:
        # ì´ì „ ëŒ€í™”ì—ì„œ ì‚¬ìš©ì íŠ¹ì„± íŒŒì•…
        for msg in prev_messages[-6:]:  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© (3í„´ ëŒ€í™”)
            if msg.role == "user":
                conversation_history += f"{user_display_name}: {msg.text}\n"
            else:
                try:
                    ai_data = json.loads(msg.text)
                    conversation_history += f"ì „ë¬¸ê°€: {ai_data.get('description', '')}\n"
                    if ai_data.get('primary_tone'):
                        user_characteristics.append(f"ì¶”ì • í†¤: {ai_data.get('primary_tone')} {ai_data.get('sub_tone')}")
                except:
                    conversation_history += f"ì „ë¬¸ê°€: {msg.text}\n"
    
    # ì‚¬ìš©ì ì§ˆë¬¸ + ëŒ€í™” íˆìŠ¤í† ë¦¬ ê²°í•©
    combined_query = f"í˜„ì¬ ì§ˆë¬¸: {request.question}\n\nì´ì „ ëŒ€í™” ë§¥ë½:\n{conversation_history}"
    
    # RAG ê²€ìƒ‰
    fixed_chunks = top_k_chunks(combined_query, fixed_index, client, k=3)
    trend_chunks = top_k_chunks(combined_query, trend_index, client, k=3)
    # Fine-tuned ê°ì • ëª¨ë¸ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ê°€ ë²„ì „)
        # ì‚¬ìš©ì ë‹‰ë„¤ì„ì„ descriptionì— ë°˜ì˜í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
    prompt_system = f"""ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ í¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ë”°ë¼ ìƒë‹´í•´ì£¼ì„¸ìš”:

ğŸ¨ ì „ë¬¸ì„±ê³¼ ì¹œê·¼í•¨ì˜ ì¡°í™”:
- í¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë¶„ì„ ì œê³µ
- ì–´ë ¤ìš´ ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- ê³ ê°({user_display_name})ì´ í¸ì•ˆí•˜ê²Œ ì§ˆë¬¸í•  ìˆ˜ ìˆë„ë¡ ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ ìœ ì§€

ï¿½ ê°ì • ê³µê° ê¸°ë°˜ ìƒë‹´:
- ê³ ê°({user_display_name})ì˜ ê³ ë¯¼ê³¼ ë‹ˆì¦ˆë¥¼ ì„¸ì‹¬í•˜ê²Œ íŒŒì•… ("ìƒ‰ê¹” ë•Œë¬¸ì— ê³ ë¯¼ì´ ë§ìœ¼ì…¨ê² ì–´ìš”")
- ìì‹ ê° ë¶€ì¡±ì´ë‚˜ ìŠ¤íƒ€ì¼ ê³ ë¯¼ì— ê³µê°í•˜ë©° ìœ„ë¡œ
- ê¸ì •ì ì¸ ë³€í™”ë¥¼ ìœ„í•œ ê²©ë ¤ì™€ ì‘ì› ë©”ì‹œì§€

ğŸŒŸ ì‹¤ìš©ì ì´ê³  ê°œì¸í™”ëœ ì¡°ì–¸:
- ê³ ê°({user_display_name})ì˜ ë¼ì´í”„ìŠ¤íƒ€ì¼, ì§ì—…, ì„ í˜¸ë„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì»¬ëŸ¬ ì¶”ì²œ
- ì˜ˆì‚°ê³¼ ìƒí™©ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì¡°ì–¸

ğŸ’¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìŠ¤íƒ€ì¼:
- ìƒë‹´ì‹¤ì—ì„œ ì§ì ‘ ëŒ€í™”í•˜ëŠ” ë“¯í•œ ìì—°ìŠ¤ëŸ¬ì›€
- "ì–´ë– ì„¸ìš”?", "~í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?" ê°™ì€ ìƒë‹´ í†¤
- ê³ ê°({user_display_name})ì´ ê¶ê¸ˆí•´í•  ì ì„ ë¨¼ì € ì˜ˆìƒí•´ì„œ ì„¤ëª…

ë‹¹ì‹ ì˜ ë›°ì–´ë‚œ ê°ì • ì´í•´ ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬, ê³ ê°({user_display_name})ì´ ì»¬ëŸ¬ì— ëŒ€í•œ ìì‹ ê°ì„ ê°–ê³  ì•„ë¦„ë‹¤ì›Œì§ˆ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”."""
    prompt_user = f"""ëŒ€í™” ë§¥ë½:\n{combined_query}\n\ní¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ ì§€ì‹:\n{chr(10).join(fixed_chunks)}\n\nìµœì‹  íŠ¸ë Œë“œ ì •ë³´:\n{chr(10).join(trend_chunks)}\n\në‹¤ìŒ ê°€ì´ë“œë¼ì¸ìœ¼ë¡œ ìƒë‹´í•´ì£¼ì„¸ìš”:
1. ê³ ê°({user_display_name})ì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•˜ê²Œ ì‘ë‹µ
2. í•„ìš”ì‹œ í¼ìŠ¤ë„ì»¬ëŸ¬ ì§„ë‹¨ì„ ìœ„í•œ ì¶”ê°€ ì§ˆë¬¸ (í”¼ë¶€í†¤, ì„ í˜¸ ìŠ¤íƒ€ì¼, ë¼ì´í”„ìŠ¤íƒ€ì¼ ë“±)
3. ëŒ€í™” íë¦„ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¬ ì¶”ì²œ
4. ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ ì œê³µ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "primary_tone": "ì›œ" ë˜ëŠ” "ì¿¨",
    "sub_tone": "ë´„" ë˜ëŠ” "ì—¬ë¦„" ë˜ëŠ” "ê°€ì„" ë˜ëŠ” "ê²¨ìš¸",
    "description": "ìƒì„¸í•œ ì„¤ëª… í…ìŠ¤íŠ¸ (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´, ê³ ê°({user_display_name})ì„ ì§ì ‘ í˜¸ëª…í•˜ë©° ì•ˆë‚´)",
    "recommendations": ["êµ¬ì²´ì ì¸ ì¶”ì²œì‚¬í•­1", "êµ¬ì²´ì ì¸ ì¶”ì²œì‚¬í•­2", "êµ¬ì²´ì ì¸ ì¶”ì²œì‚¬í•­3"]
}}

ì£¼ì˜: recommendationsëŠ” ë°˜ë“œì‹œ ë¬¸ìì—´ ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
"""
    messages = [{"role": "system", "content": prompt_system}, {"role": "user", "content": prompt_user}]
    
    # ëª¨ë¸ ì„ íƒ í•¨ìˆ˜ ì‚¬ìš©
    print(f"ğŸ¤– Using model: {get_model_to_use()[:30]}***")  # ë””ë²„ê¹…ìš© ë¡œê·¸
    try:
        resp = client.chat.completions.create(
            model=get_model_to_use(),
            messages=messages,
            temperature=0.8,  # ê°ì • ëª¨ë¸ì—ì„œëŠ” ì¢€ ë” ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìœ„í•´ temperature ìƒí–¥
            max_tokens=600
        )
    except Exception as e:
        print(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"AI ì„œë¹„ìŠ¤ ì¼ì‹œì  ì˜¤ë¥˜: {str(e)}")
    content = resp.choices[0].message.content
    start, end = content.find("{"), content.rfind("}")
    
    # ëŒ€í™”ë¥¼ í†µí•œ í¼ìŠ¤ë„ì»¬ëŸ¬ ì§„ë‹¨ (ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©)
    primary_tone, sub_tone = analyze_conversation_for_color_tone(conversation_history, request.question)
    
    # JSON íŒŒì‹± ì‹œë„
    if start != -1 and end != -1:
        try:
            data = json.loads(content[start:end+1])
            # ëŒ€í™” ë¶„ì„ ê²°ê³¼ë¡œ í†¤ ì •ë³´ ì„¤ì •
            data["primary_tone"] = primary_tone
            data["sub_tone"] = sub_tone
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
            data = {
                "primary_tone": primary_tone,
                "sub_tone": sub_tone,
                "description": content.strip(),
                "recommendations": ["ë” ìì„¸í•œ ì •ë³´ë¥¼ ìœ„í•´ í”¼ë¶€í†¤ì´ë‚˜ ì„ í˜¸í•˜ëŠ” ìƒ‰ê¹”ì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”.", "í‰ì†Œ ì–´ë–¤ ìŠ¤íƒ€ì¼ì„ ì¢‹ì•„í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ë¶„ì„ì„ ë„ì™€ë“œë¦´ê²Œìš”.", "ê¶ê¸ˆí•œ ì»¬ëŸ¬ë‚˜ ìŠ¤íƒ€ì¼ì— ëŒ€í•´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"]
            }
    else:
        # JSON í˜•ì‹ì´ ì „í˜€ ì—†ëŠ” ê²½ìš° fallback
        data = {
            "primary_tone": primary_tone,
            "sub_tone": sub_tone, 
            "description": content.strip() if content.strip() else "ì•ˆë…•í•˜ì„¸ìš”! í¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì–´ë–¤ ì»¬ëŸ¬ë‚˜ ìŠ¤íƒ€ì¼ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”? í”¼ë¶€í†¤, ì¢‹ì•„í•˜ëŠ” ìƒ‰ê¹”, í‰ì†Œ ìŠ¤íƒ€ì¼ ë“± ì–´ë–¤ ê²ƒì´ë“  í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”!",
            "recommendations": ["í”¼ë¶€í†¤ì´ë‚˜ í˜ˆê´€ ìƒ‰ê¹”ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.", "í‰ì†Œ ì–´ë–¤ ìƒ‰ê¹” ì˜·ì„ ì¦ê²¨ ì…ìœ¼ì‹œëŠ”ì§€ ë§ì”€í•´ì£¼ì„¸ìš”.", "ë©”ì´í¬ì—…ì´ë‚˜ í—¤ì–´ ì»¬ëŸ¬ ê´€ë ¨í•´ì„œë„ ë„ì›€ë“œë¦´ ìˆ˜ ìˆì–´ìš”."]
        }
    # ê°ì • ì´ëª¨í‹°ì½˜ ë¶„ì„ ë° ì¶”ê°€
    user_emotion = detect_emotion(request.question)
    data["emotion"] = user_emotion
    
    # recommendations í•„ë“œ ì •ë¦¬
    recommendations = data.get("recommendations", [])
    if isinstance(recommendations, dict):
        recommendations = list(recommendations.values())
    elif isinstance(recommendations, list):
        # ì¤‘ì²©ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ í‰í‰í•˜ê²Œ ë§Œë“¤ê¸°
        flattened_recommendations = []
        for item in recommendations:
            if isinstance(item, list):
                flattened_recommendations.extend(item)
            elif isinstance(item, str):
                flattened_recommendations.append(item)
        recommendations = flattened_recommendations
    else:
        recommendations = []
    
    data["recommendations"] = recommendations
    ai_msg = models.ChatMessage(history_id=chat_history.id, role="ai", text=json.dumps(data, ensure_ascii=False))
    db.add(ai_msg)
    db.commit()
    db.refresh(ai_msg)

    # AI ë‹µë³€ ì €ì¥ í›„, AI í”¼ë“œë°± ìë™ í‰ê°€ ì‹¤í–‰ (ì±„íŒ… ì¢…ë£Œ ì „ì—ë„ í‰ê°€ ê°€ëŠ¥í•˜ë„ë¡ ì˜ˆì™¸ ë¬´ì‹œ)
    try:
        generate_ai_feedbacks(history_id=chat_history.id, current_user=current_user, db=db)
    except Exception as e:
        # ì˜ˆ: ì±„íŒ… ì¢…ë£Œ ì „ì—ëŠ” í‰ê°€ ë¶ˆê°€ ë“±ì˜ ì˜ˆì™¸ ë°œìƒ ê°€ëŠ¥, ë¬´ì‹œí•˜ê³  ì§„í–‰
        pass
    msgs = db.query(models.ChatMessage).filter_by(history_id=chat_history.id).order_by(models.ChatMessage.id.asc()).all()
    items = []
    qid = 1
    for i in range(0,len(msgs)-1,2):
        if msgs[i].role=="user" and msgs[i+1].role=="ai":
            d = json.loads(msgs[i+1].text)
            # ê¸°ì¡´ ë°ì´í„°ì˜ recommendations í•„ë“œë„ ì •ë¦¬
            recommendations = d.get("recommendations", [])
            if isinstance(recommendations, dict):
                recommendations = list(recommendations.values())
            elif isinstance(recommendations, list):
                flattened_recommendations = []
                for item in recommendations:
                    if isinstance(item, list):
                        flattened_recommendations.extend(item)
                    elif isinstance(item, str):
                        flattened_recommendations.append(item)
                recommendations = flattened_recommendations
            else:
                recommendations = []
            d["recommendations"] = recommendations
            items.append(ChatItemModel(
                question_id=qid,
                question=msgs[i].text,
                answer=d.get("description",""),
                chat_res=ChatResModel.model_validate(d),
                emotion=d.get("emotion", "wink")
            ))
            qid += 1
    return {"history_id": chat_history.id, "items": items}


@router.post("/start")
def start_chat_session(
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """
    ëª…ì‹œì ìœ¼ë¡œ ìƒˆ ì±„íŒ… ì„¸ì…˜ì„ ìƒì„±í•˜ê³  history_idë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    í”„ë¡ íŠ¸ì—”ë“œê°€ í˜ì´ì§€ ì§„ì… ì‹œ ì´ ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬
    ê¸°ì¡´ ì—´ë¦° ì„¸ì…˜ê³¼ ê´€ê³„ì—†ì´ í•­ìƒ ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì‹œì‘í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    """
    # DB-level concurrency handling:
    # Acquire a FOR UPDATE lock on the user row, then check for an open ChatHistory.
    # This prevents two concurrent requests from both observing "no open session" and
    # creating duplicate open sessions. Locking the user row is lightweight and
    # avoids requiring DB schema changes (partial unique indexes) here.
    try:
        # Lock the user row for this transaction
        db.query(models.User).filter(models.User.id == current_user.id).with_for_update().first()

        # Now check again for an existing open session while holding the lock
        existing = db.query(models.ChatHistory).filter(
            models.ChatHistory.user_id == current_user.id,
            models.ChatHistory.ended_at == None,
        ).order_by(models.ChatHistory.created_at.desc()).first()

        if existing:
            user_turns = db.query(models.ChatMessage).filter_by(history_id=existing.id, role='user').count()
            print(f"ğŸ” ê¸°ì¡´ ì—´ë¦° ì„¸ì…˜ ì¬ì‚¬ìš©: user_id={current_user.id}, history_id={existing.id}, user_turns={user_turns}")
            return {"history_id": existing.id, "reused": True, "user_turns": user_turns}

        # No existing open session found while holding the lock: create one
        chat_history = models.ChatHistory(user_id=current_user.id)
        db.add(chat_history)
        db.commit()
        db.refresh(chat_history)
        print(f"â• ìƒˆ ì±„íŒ… ì„¸ì…˜ ìƒì„±: user_id={current_user.id}, history_id={chat_history.id}")
        return {"history_id": chat_history.id, "reused": False, "user_turns": 0}

    except Exception as e:
        # Roll back on error and return a 500 so clients can retry safely
        print(f"âŒ /start ì˜¤ë¥˜ ë°œìƒ: {e}")
        try:
            db.rollback()
        except:
            pass
        raise HTTPException(status_code=500, detail="ì±„íŒ… ì„¸ì…˜ ìƒì„± ì¤‘ DB ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.post("/end/{history_id}")
async def end_chat_session(
    history_id: int,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    chat = db.query(models.ChatHistory).filter_by(id=history_id, user_id=current_user.id).first()
    if not chat:
        raise HTTPException(status_code=404, detail="ëŒ€í™” ì„¸ì…˜ ì—†ìŒ")
    if chat.ended_at:
        return {"message": "ì´ë¯¸ ì¢…ë£Œë¨", "ended_at": chat.ended_at}
    
    # ëŒ€í™” ì¢…ë£Œ ì‹œê°„ ì„¤ì •
    chat.ended_at = datetime.now(timezone.utc)
    db.commit()
    
    # ì±—ë´‡ ëŒ€í™” ë¶„ì„ ê²°ê³¼ë¥¼ SurveyResultë¡œ ì €ì¥
    try:
        survey_result = await save_chatbot_analysis_result(
            user_id=current_user.id,
            chat_history_id=history_id,
            db=db
        )
        
        if survey_result:
            return {
                "message": "ëŒ€í™” ì¢…ë£Œ ë° ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ", 
                "ended_at": chat.ended_at,
                "survey_result_id": survey_result.id,
                "personal_color_type": survey_result.result_tone
            }
        else:
            return {
                "message": "ëŒ€í™” ì¢…ë£Œë¨ (ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨)", 
                "ended_at": chat.ended_at
            }
            
    except Exception as e:
        print(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "message": "ëŒ€í™” ì¢…ë£Œë¨ (ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ)", 
            "ended_at": chat.ended_at
        }


@router.post("/report/request")
async def request_personal_color_report(
    request_data: dict,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    ğŸ”¥ ê¸°ì¡´ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨ ë³´ê³ ì„œ ìƒì„± ìš”ì²­ ğŸ”¥
    
    âš ï¸ ì¤‘ìš”: ì´ APIëŠ” ìƒˆë¡œìš´ ì§„ë‹¨ ê¸°ë¡ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!
    - ê¸°ì¡´ ì§„ë‹¨ ê²°ê³¼(SurveyResult)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬í¬íŠ¸ë§Œ ìƒì„±
    - ì§„ë‹¨ ê¸°ë¡(ë§ˆì´í˜ì´ì§€)ì— ìƒˆë¡œìš´ í•­ëª©ì´ ì¶”ê°€ë˜ì§€ ì•ŠìŒ
    - ë‹¨ìˆœíˆ ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‹œê°í™”/í¬ë§·íŒ…í•˜ì—¬ ë¦¬í¬íŠ¸ë¡œ ì œê³µ
    
    ìƒˆë¡œìš´ ì§„ë‹¨ ê¸°ë¡ì€ ì˜¤ì§ ëŒ€í™”í˜• ë¶„ì„ì„ í†µí•´ì„œë§Œ ìƒì„±ë©ë‹ˆë‹¤.
    """
    survey_result_id = request_data.get("history_id")  # ì‹¤ì œë¡œëŠ” survey_result_id
    
    if not survey_result_id:
        raise HTTPException(status_code=400, detail="ì§„ë‹¨ ê²°ê³¼ IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
    
    # ì‚¬ìš©ìì˜ ê¸°ì¡´ ì§„ë‹¨ ê²°ê³¼ ì¡°íšŒ (ì½ê¸° ì „ìš©)
    survey_result = db.query(models.SurveyResult).filter_by(
        id=survey_result_id, 
        user_id=current_user.id, 
        is_active=True
    ).first()
    
    if not survey_result:
        raise HTTPException(status_code=404, detail="ì§„ë‹¨ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    print(f"ğŸ“Š ê¸°ì¡´ ì§„ë‹¨ ê²°ê³¼ ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„±: survey_result_id={survey_result_id}")
    print(f"   - ê²°ê³¼ íƒ€ì…: {survey_result.result_tone}")
    print(f"   - ìƒì„±ì¼: {survey_result.created_at}")
    print(f"   â— ìƒˆë¡œìš´ ì§„ë‹¨ ê¸°ë¡ì„ ìƒì„±í•˜ì§€ ì•ŠìŒ (ë¦¬í¬íŠ¸ë§Œ ìƒì„±)")
    
    try:
        from utils.report_generator import PersonalColorReportGenerator
        
        # ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”
        report_generator = PersonalColorReportGenerator()
        
        # ê¸°ì¡´ ì§„ë‹¨ ê²°ê³¼ë¥¼ ë¦¬í¬íŠ¸ ë°ì´í„°ë¡œ ë³€í™˜ (ì½ê¸° ì „ìš©)
        survey_data = {
            "result_tone": survey_result.result_tone,
            "result_name": survey_result.result_name,
            "confidence": survey_result.confidence,
            "detailed_analysis": survey_result.detailed_analysis,
            "color_palette": survey_result.color_palette,
            "style_keywords": survey_result.style_keywords,
            "makeup_tips": survey_result.makeup_tips
        }
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ë¦¬í¬íŠ¸ì— í¬í•¨í•  ëŒ€í™” ë‚´ìš©, ì½ê¸° ì „ìš©)
        chat_history = []
        if hasattr(survey_result, 'chat_history_id') and survey_result.chat_history_id:
            messages = db.query(models.ChatMessage).filter_by(
                history_id=survey_result.chat_history_id
            ).order_by(models.ChatMessage.created_at.asc()).all()
            
            chat_history = [
                {
                    "role": msg.role,
                    "text": msg.text,
                    "created_at": msg.created_at.isoformat()
                }
                for msg in messages
            ]
        
        # ë¦¬í¬íŠ¸ ë°ì´í„° ìƒì„± (ê¸°ì¡´ ë°ì´í„° ì‹œê°í™”ë§Œ, DB ë³€ê²½ ì—†ìŒ)
        report_data = report_generator.generate_report_data(survey_data, chat_history)
        
        # âš ï¸ ì¤‘ìš”: ì—¬ê¸°ì„œ db.add(), db.commit() ë“±ì˜ DB ë³€ê²½ ì‘ì—… ì ˆëŒ€ ê¸ˆì§€!
        print(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ (DB ë³€ê²½ ì—†ìŒ)")
        
        return {
            "status": "success",
            "message": f"{survey_result.result_name or survey_result.result_tone.upper()} íƒ€ì… ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
            "survey_result_id": survey_result_id,
            "report_data": report_data,
            "note": "ê¸°ì¡´ ì§„ë‹¨ ë°ì´í„° ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± (ìƒˆë¡œìš´ ì§„ë‹¨ ê¸°ë¡ ì¶”ê°€ ì—†ìŒ)"
        }
        
    except Exception as e:
        print(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.get("/report/{survey_result_id}")
async def get_personal_color_report(
    survey_result_id: int,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    ìƒì„±ëœ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨ ë³´ê³ ì„œ ì¡°íšŒ
    """
    survey_result = db.query(models.SurveyResult).filter_by(
        id=survey_result_id, 
        user_id=current_user.id, 
        is_active=True
    ).first()
    
    if not survey_result:
        raise HTTPException(status_code=404, detail="ì§„ë‹¨ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        from utils.report_generator import PersonalColorReportGenerator
        
        report_generator = PersonalColorReportGenerator()
        
        # ì§„ë‹¨ ê²°ê³¼ ë°ì´í„° ì¤€ë¹„
        survey_data = {
            "result_tone": survey_result.result_tone,
            "result_name": survey_result.result_name,
            "confidence": survey_result.confidence,
            "detailed_analysis": survey_result.detailed_analysis,
            "color_palette": survey_result.color_palette,
            "style_keywords": survey_result.style_keywords,
            "makeup_tips": survey_result.makeup_tips
        }
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
        chat_history = []
        
        # ë¦¬í¬íŠ¸ ë°ì´í„° ìƒì„±
        report_data = report_generator.generate_report_data(survey_data, chat_history)
        
        # HTML ë¦¬í¬íŠ¸ë„ ìƒì„±
        html_report = report_generator.generate_html_report(report_data)
        
        return {
            "message": "ë¦¬í¬íŠ¸ ì¡°íšŒ ì„±ê³µ",
            "report_data": report_data,
            "html_report": html_report,
            "download_available": True
        }
        
    except Exception as e:
        print(f"âŒ ë¦¬í¬íŠ¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë¦¬í¬íŠ¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
