from fastapi import APIRouter, HTTPException, Depends, status
from openai import OpenAI
from dotenv import load_dotenv
from sqlalchemy.orm import Session
from datetime import datetime, timezone
import models
from routers.user_router import get_current_user
from database import SessionLocal
import os, json


from schemas import ChatbotRequest, ChatbotHistoryResponse, ChatItemModel, ChatResModel
# AI í”¼ë“œë°± ìë™ í‰ê°€ í•¨ìˆ˜ ì„í¬íŠ¸
from routers.feedback_router import generate_ai_feedbacks
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
from utils.shared import (
    top_k_chunks, 
    build_rag_index, 
    analyze_conversation_for_color_tone
)

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ê°ì • ë¶„ì„ Fine-tuned ëª¨ë¸ ì„¤ì •
EMOTION_MODEL_ID = os.getenv("EMOTION_MODEL_ID")
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "gpt-4.1-nano-2025-04-14")

client = OpenAI(api_key=OPENAI_API_KEY)
router = APIRouter(prefix="/api/chatbot", tags=["Chatbot"])

# ëª¨ë¸ ìƒíƒœ ì¶œë ¥
print(f"ğŸš€ Chatbot Router ì´ˆê¸°í™”")
print(f"   - ê¸°ë³¸ ëª¨ë¸: {DEFAULT_MODEL}")
if EMOTION_MODEL_ID:
    print(f"   - Fine-tuned ê°ì • ëª¨ë¸: {EMOTION_MODEL_ID[:30]}***")
    print(f"   âœ… Fine-tuned ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
else:
    print(f"   âš ï¸ Fine-tuned ëª¨ë¸ ë¯¸ì„¤ì •, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# RAG ì¸ë±ìŠ¤ êµ¬ì¶• (ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰)
fixed_index = build_rag_index(client, "data/RAG/personal_color_RAG.txt")

async def save_chatbot_analysis_result(
    user_id: int, 
    chat_history_id: int,
    db: Session
):
    """
    ì±—ë´‡ ëŒ€í™” ë¶„ì„ì„ í†µí•´ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨ ê²°ê³¼ë¥¼ SurveyResultì— ì €ì¥
    """
    try:
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì—ì„œ ë©”ì‹œì§€ë“¤ ê°€ì ¸ì˜¤ê¸°
        messages = db.query(models.ChatMessage).filter_by(
            history_id=chat_history_id
        ).order_by(models.ChatMessage.created_at.asc()).all()
        
        if not messages:
            return None
            
        # ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í¼ìŠ¤ë„ ì»¬ëŸ¬ ê²°ì •
        conversation_text = ""
        for msg in messages:
            if msg.role == "user":
                conversation_text += f"User: {msg.text}\n"
            elif msg.role == "ai":
                try:
                    ai_data = json.loads(msg.text)
                    conversation_text += f"AI: {ai_data.get('description', msg.text)}\n"
                except:
                    conversation_text += f"AI: {msg.text}\n"
        
        # ëŒ€í™” ë¶„ì„ì„ í†µí•œ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨
        color_analysis = analyze_conversation_for_color_tone(
            client, conversation_text, fixed_index
        )
        
        if not color_analysis:
            return None
            
        # AIê°€ ë¶„ì„í•œ ìµœì¢… ê²°ê³¼ì—ì„œ ì •ë³´ ì¶”ì¶œ
        primary_type = color_analysis.get("primary_type", "spring")
        confidence = color_analysis.get("confidence", 0.8)
        
        # í¼ìŠ¤ë„ ì»¬ëŸ¬ íƒ€ì…ë³„ ê¸°ë³¸ ì •ë³´
        color_type_info = {
            "spring": {
                "name": "ë´„ ì›œí†¤ ğŸŒ¸",
                "description": "ìƒê¸° ë„˜ì¹˜ê³  í™”ì‚¬í•œ ë‹¹ì‹ ! ë°ê³  ë”°ëœ»í•œ ìƒ‰ìƒì´ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.",
                "color_palette": ["#FFB6C1", "#FFA07A", "#FFFF99", "#98FB98", "#87CEEB"],
                "style_keywords": ["ë°ì€", "í™”ì‚¬í•œ", "ìƒê¸°ìˆëŠ”", "ë”°ëœ»í•œ", "ìƒë™ê°"],
                "makeup_tips": ["ì½”ë„ ê³„ì—´ ë¦½", "í”¼ì¹˜ ê³„ì—´ ë¸”ëŸ¬ì…”", "ë¸Œë¼ìš´ ê³„ì—´ ì•„ì´ì„€ë„ìš°"]
            },
            "summer": {
                "name": "ì—¬ë¦„ ì¿¨í†¤ ğŸ’",
                "description": "ì‹œì›í•˜ê³  ìš°ì•„í•œ ë‹¹ì‹ ! ë¶€ë“œëŸ½ê³  ì°¨ê°€ìš´ ìƒ‰ìƒì´ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.",
                "color_palette": ["#E6E6FA", "#B0C4DE", "#FFC0CB", "#DDA0DD", "#F0F8FF"],
                "style_keywords": ["ìš°ì•„í•œ", "ì‹œì›í•œ", "ë¶€ë“œëŸ¬ìš´", "ì„¸ë ¨ëœ", "ì°¨ë¶„í•œ"],
                "makeup_tips": ["ë¡œì¦ˆ ê³„ì—´ ë¦½", "í•‘í¬ ê³„ì—´ ë¸”ëŸ¬ì…”", "ì¿¨í†¤ ì•„ì´ì„€ë„ìš°"]
            },
            "autumn": {
                "name": "ê°€ì„ ì›œí†¤ ğŸ‚",
                "description": "ê¹Šì´ ìˆê³  ì„¸ë ¨ëœ ë‹¹ì‹ ! ì§„í•˜ê³  ë”°ëœ»í•œ ìƒ‰ìƒì´ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.",
                "color_palette": ["#D2691E", "#CD853F", "#DEB887", "#BC8F8F", "#F4A460"],
                "style_keywords": ["ê¹Šì´ìˆëŠ”", "ì„¸ë ¨ëœ", "ë”°ëœ»í•œ", "ê³ ê¸‰ìŠ¤ëŸ¬ìš´", "ì•ˆì •ì "],
                "makeup_tips": ["ë²½ëŒìƒ‰ ê³„ì—´ ë¦½", "ë¸Œë¡ ì¦ˆ ê³„ì—´ ë¸”ëŸ¬ì…”", "ë¸Œë¼ìš´ ê³„ì—´ ì•„ì´ì„€ë„ìš°"]
            },
            "winter": {
                "name": "ê²¨ìš¸ ì¿¨í†¤ â„ï¸",
                "description": "ëª…í™•í•˜ê³  ê°•ë ¬í•œ ë‹¹ì‹ ! ì„ ëª…í•˜ê³  ì°¨ê°€ìš´ ìƒ‰ìƒì´ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.",
                "color_palette": ["#FF1493", "#4169E1", "#000000", "#FFFFFF", "#8A2BE2"],
                "style_keywords": ["ëª…í™•í•œ", "ê°•ë ¬í•œ", "ì„ ëª…í•œ", "ëª¨ë˜í•œ", "ì‹œí¬í•œ"],
                "makeup_tips": ["ë ˆë“œ ê³„ì—´ ë¦½", "ì¿¨í†¤ ë¸”ëŸ¬ì…”", "ì§„í•œ ì•„ì´ë©”ì´í¬ì—…"]
            }
        }
        
        type_info = color_type_info.get(primary_type, color_type_info["spring"])
        
        # Top types ìƒì„± (ì‹ ë¢°ë„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ë¥¸ íƒ€ì…ë“¤ë„ í¬í•¨)
        top_types = [
            {
                "type": primary_type,
                "name": type_info["name"],
                "description": type_info["description"],
                "color_palette": type_info["color_palette"],
                "style_keywords": type_info["style_keywords"],
                "makeup_tips": type_info["makeup_tips"],
                "score": int(confidence * 100)
            }
        ]
        
        # SurveyResultë¡œ ì €ì¥
        survey_result = models.SurveyResult(
            user_id=user_id,
            result_tone=primary_type,
            confidence=confidence,
            total_score=int(confidence * 100),
            source_type="chatbot",  # ì±—ë´‡ ë¶„ì„ ì¶œì²˜ í‘œì‹œ
            detailed_analysis=color_analysis.get("analysis", "AI ì±—ë´‡ì„ í†µí•œ ëŒ€í™”í˜• í¼ìŠ¤ë„ ì»¬ëŸ¬ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."),
            result_name=type_info["name"],
            result_description=type_info["description"],
            color_palette=json.dumps(type_info["color_palette"], ensure_ascii=False),
            style_keywords=json.dumps(type_info["style_keywords"], ensure_ascii=False),
            makeup_tips=json.dumps(type_info["makeup_tips"], ensure_ascii=False),
            top_types=json.dumps(top_types, ensure_ascii=False)
        )
        
        db.add(survey_result)
        db.commit()
        db.refresh(survey_result)
        
        return survey_result
        
    except Exception as e:
        print(f"âŒ ì±—ë´‡ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        db.rollback()
        return None
trend_index = build_rag_index(client, "data/RAG/beauty_trend_2025_autumn_RAG.txt")

@router.post("/analyze", response_model=ChatbotHistoryResponse)
def analyze(
    request: ChatbotRequest,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # ì‹ ê·œ ì„¸ì…˜ ìƒì„± ë˜ëŠ” ê¸°ì¡´ ì„¸ì…˜ ì´ì–´ë°›ê¸°
    if not request.history_id:
        chat_history = models.ChatHistory(user_id=current_user.id)
        db.add(chat_history)
        db.commit()
        db.refresh(chat_history)
    else:
        chat_history = db.query(models.ChatHistory).filter_by(id=request.history_id, user_id=current_user.id).first()
        if not chat_history:
            raise HTTPException(status_code=404, detail="í•´ë‹¹ history_id ì„¸ì…˜ ì—†ìŒ")
        if chat_history.ended_at:
            raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¢…ë£Œëœ ì„¸ì…˜ì…ë‹ˆë‹¤.")
    prev_questions = db.query(models.ChatMessage).filter_by(history_id=chat_history.id, role="user").order_by(models.ChatMessage.id.asc()).all()
    question_id = len(prev_questions) + 1
    user_msg = models.ChatMessage(history_id=chat_history.id, role="user", text=request.question)
    db.add(user_msg)
    db.commit()
    db.refresh(user_msg)
    # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ì—ì„œ ì‚¬ìš©ì ì •ë³´ ìˆ˜ì§‘
    prev_messages = db.query(models.ChatMessage).filter_by(history_id=chat_history.id).order_by(models.ChatMessage.id.asc()).all()
    conversation_history = ""
    user_characteristics = []
    
    if prev_messages:
        # ì´ì „ ëŒ€í™”ì—ì„œ ì‚¬ìš©ì íŠ¹ì„± íŒŒì•…
        for msg in prev_messages[-6:]:  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© (3í„´ ëŒ€í™”)
            if msg.role == "user":
                conversation_history += f"ì‚¬ìš©ì: {msg.text}\n"
            else:
                try:
                    ai_data = json.loads(msg.text)
                    conversation_history += f"ì „ë¬¸ê°€: {ai_data.get('description', '')}\n"
                    if ai_data.get('primary_tone'):
                        user_characteristics.append(f"ì¶”ì • í†¤: {ai_data.get('primary_tone')} {ai_data.get('sub_tone')}")
                except:
                    conversation_history += f"ì „ë¬¸ê°€: {msg.text}\n"
    
    # ì‚¬ìš©ì ì§ˆë¬¸ + ëŒ€í™” íˆìŠ¤í† ë¦¬ ê²°í•©
    combined_query = f"í˜„ì¬ ì§ˆë¬¸: {request.question}\n\nì´ì „ ëŒ€í™” ë§¥ë½:\n{conversation_history}"
    
    # RAG ê²€ìƒ‰
    fixed_chunks = top_k_chunks(combined_query, fixed_index, client, k=3)
    trend_chunks = top_k_chunks(combined_query, trend_index, client, k=3)
    # Fine-tuned ê°ì • ëª¨ë¸ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ê°€ ë²„ì „)
    prompt_system = """ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ í¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ë”°ë¼ ìƒë‹´í•´ì£¼ì„¸ìš”:

ğŸ¨ ì „ë¬¸ì„±ê³¼ ì¹œê·¼í•¨ì˜ ì¡°í™”:
- í¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë¶„ì„ ì œê³µ
- ì–´ë ¤ìš´ ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- ê³ ê°ì´ í¸ì•ˆí•˜ê²Œ ì§ˆë¬¸í•  ìˆ˜ ìˆë„ë¡ ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ ìœ ì§€

ï¿½ ê°ì • ê³µê° ê¸°ë°˜ ìƒë‹´:
- ê³ ê°ì˜ ê³ ë¯¼ê³¼ ë‹ˆì¦ˆë¥¼ ì„¸ì‹¬í•˜ê²Œ íŒŒì•… ("ìƒ‰ê¹” ë•Œë¬¸ì— ê³ ë¯¼ì´ ë§ìœ¼ì…¨ê² ì–´ìš”")
- ìì‹ ê° ë¶€ì¡±ì´ë‚˜ ìŠ¤íƒ€ì¼ ê³ ë¯¼ì— ê³µê°í•˜ë©° ìœ„ë¡œ
- ê¸ì •ì ì¸ ë³€í™”ë¥¼ ìœ„í•œ ê²©ë ¤ì™€ ì‘ì› ë©”ì‹œì§€

ğŸŒŸ ì‹¤ìš©ì ì´ê³  ê°œì¸í™”ëœ ì¡°ì–¸:
- ê³ ê°ì˜ ë¼ì´í”„ìŠ¤íƒ€ì¼, ì§ì—…, ì„ í˜¸ë„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì»¬ëŸ¬ ì¶”ì²œ
- ì˜ˆì‚°ê³¼ ìƒí™©ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì¡°ì–¸

ğŸ’¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìŠ¤íƒ€ì¼:
- ìƒë‹´ì‹¤ì—ì„œ ì§ì ‘ ëŒ€í™”í•˜ëŠ” ë“¯í•œ ìì—°ìŠ¤ëŸ¬ì›€
- "ì–´ë– ì„¸ìš”?", "~í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?" ê°™ì€ ìƒë‹´ í†¤
- ê³ ê°ì´ ê¶ê¸ˆí•´í•  ì ì„ ë¨¼ì € ì˜ˆìƒí•´ì„œ ì„¤ëª…

ë‹¹ì‹ ì˜ ë›°ì–´ë‚œ ê°ì • ì´í•´ ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬, ê³ ê°ì´ ì»¬ëŸ¬ì— ëŒ€í•œ ìì‹ ê°ì„ ê°–ê³  ì•„ë¦„ë‹¤ì›Œì§ˆ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”."""
    prompt_user = f"""ëŒ€í™” ë§¥ë½:\n{combined_query}\n\ní¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ ì§€ì‹:\n{chr(10).join(fixed_chunks)}\n\nìµœì‹  íŠ¸ë Œë“œ ì •ë³´:\n{chr(10).join(trend_chunks)}\n\në‹¤ìŒ ê°€ì´ë“œë¼ì¸ìœ¼ë¡œ ìƒë‹´í•´ì£¼ì„¸ìš”:
1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•˜ê²Œ ì‘ë‹µ
2. í•„ìš”ì‹œ í¼ìŠ¤ë„ì»¬ëŸ¬ ì§„ë‹¨ì„ ìœ„í•œ ì¶”ê°€ ì§ˆë¬¸ (í”¼ë¶€í†¤, ì„ í˜¸ ìŠ¤íƒ€ì¼, ë¼ì´í”„ìŠ¤íƒ€ì¼ ë“±)
3. ëŒ€í™” íë¦„ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¬ ì¶”ì²œ
4. ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ ì œê³µ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "primary_tone": "ì›œ" ë˜ëŠ” "ì¿¨",
  "sub_tone": "ë´„" ë˜ëŠ” "ì—¬ë¦„" ë˜ëŠ” "ê°€ì„" ë˜ëŠ” "ê²¨ìš¸",
  "description": "ìƒì„¸í•œ ì„¤ëª… í…ìŠ¤íŠ¸ (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´)",
  "recommendations": ["êµ¬ì²´ì ì¸ ì¶”ì²œì‚¬í•­1", "êµ¬ì²´ì ì¸ ì¶”ì²œì‚¬í•­2", "êµ¬ì²´ì ì¸ ì¶”ì²œì‚¬í•­3"]
}}

ì£¼ì˜: recommendationsëŠ” ë°˜ë“œì‹œ ë¬¸ìì—´ ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
"""
    messages = [{"role": "system", "content": prompt_system}, {"role": "user", "content": prompt_user}]
    
    # Fine-tuned ê°ì • ëª¨ë¸ ì‚¬ìš© (ì—†ìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ë¡œ fallback)
    model_to_use = EMOTION_MODEL_ID if EMOTION_MODEL_ID else DEFAULT_MODEL
    print(f"ğŸ¤– Using model: {model_to_use[:30]}***")  # ë””ë²„ê¹…ìš© ë¡œê·¸
    
    try:
        resp = client.chat.completions.create(
            model=model_to_use, 
            messages=messages, 
            temperature=0.8,  # ê°ì • ëª¨ë¸ì—ì„œëŠ” ì¢€ ë” ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìœ„í•´ temperature ìƒí–¥
            max_tokens=600
        )
    except Exception as e:
        print(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"AI ì„œë¹„ìŠ¤ ì¼ì‹œì  ì˜¤ë¥˜: {str(e)}")
    content = resp.choices[0].message.content
    start, end = content.find("{"), content.rfind("}")
    
    # ëŒ€í™”ë¥¼ í†µí•œ í¼ìŠ¤ë„ì»¬ëŸ¬ ì§„ë‹¨ (ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©)
    primary_tone, sub_tone = analyze_conversation_for_color_tone(conversation_history, request.question)
    
    # JSON íŒŒì‹± ì‹œë„
    if start != -1 and end != -1:
        try:
            data = json.loads(content[start:end+1])
            # ëŒ€í™” ë¶„ì„ ê²°ê³¼ë¡œ í†¤ ì •ë³´ ì„¤ì •
            data["primary_tone"] = primary_tone
            data["sub_tone"] = sub_tone
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
            data = {
                "primary_tone": primary_tone,
                "sub_tone": sub_tone,
                "description": content.strip(),
                "recommendations": ["ë” ìì„¸í•œ ì •ë³´ë¥¼ ìœ„í•´ í”¼ë¶€í†¤ì´ë‚˜ ì„ í˜¸í•˜ëŠ” ìƒ‰ê¹”ì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”.", "í‰ì†Œ ì–´ë–¤ ìŠ¤íƒ€ì¼ì„ ì¢‹ì•„í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ë¶„ì„ì„ ë„ì™€ë“œë¦´ê²Œìš”.", "ê¶ê¸ˆí•œ ì»¬ëŸ¬ë‚˜ ìŠ¤íƒ€ì¼ì— ëŒ€í•´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"]
            }
    else:
        # JSON í˜•ì‹ì´ ì „í˜€ ì—†ëŠ” ê²½ìš° fallback
        data = {
            "primary_tone": primary_tone,
            "sub_tone": sub_tone, 
            "description": content.strip() if content.strip() else "ì•ˆë…•í•˜ì„¸ìš”! í¼ìŠ¤ë„ì»¬ëŸ¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì–´ë–¤ ì»¬ëŸ¬ë‚˜ ìŠ¤íƒ€ì¼ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”? í”¼ë¶€í†¤, ì¢‹ì•„í•˜ëŠ” ìƒ‰ê¹”, í‰ì†Œ ìŠ¤íƒ€ì¼ ë“± ì–´ë–¤ ê²ƒì´ë“  í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”!",
            "recommendations": ["í”¼ë¶€í†¤ì´ë‚˜ í˜ˆê´€ ìƒ‰ê¹”ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.", "í‰ì†Œ ì–´ë–¤ ìƒ‰ê¹” ì˜·ì„ ì¦ê²¨ ì…ìœ¼ì‹œëŠ”ì§€ ë§ì”€í•´ì£¼ì„¸ìš”.", "ë©”ì´í¬ì—…ì´ë‚˜ í—¤ì–´ ì»¬ëŸ¬ ê´€ë ¨í•´ì„œë„ ë„ì›€ë“œë¦´ ìˆ˜ ìˆì–´ìš”."]
        }
    
    # recommendations í•„ë“œ ì •ë¦¬
    recommendations = data.get("recommendations", [])
    if isinstance(recommendations, dict):
        recommendations = list(recommendations.values())
    elif isinstance(recommendations, list):
        # ì¤‘ì²©ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ í‰í‰í•˜ê²Œ ë§Œë“¤ê¸°
        flattened_recommendations = []
        for item in recommendations:
            if isinstance(item, list):
                flattened_recommendations.extend(item)
            elif isinstance(item, str):
                flattened_recommendations.append(item)
        recommendations = flattened_recommendations
    else:
        recommendations = []
    
    data["recommendations"] = recommendations
    answer_string = data.get("description","")
    ai_msg = models.ChatMessage(history_id=chat_history.id, role="ai", text=json.dumps(data, ensure_ascii=False))
    db.add(ai_msg)
    db.commit()
    db.refresh(ai_msg)

    # AI ë‹µë³€ ì €ì¥ í›„, AI í”¼ë“œë°± ìë™ í‰ê°€ ì‹¤í–‰ (ì±„íŒ… ì¢…ë£Œ ì „ì—ë„ í‰ê°€ ê°€ëŠ¥í•˜ë„ë¡ ì˜ˆì™¸ ë¬´ì‹œ)
    try:
        generate_ai_feedbacks(history_id=chat_history.id, current_user=current_user, db=db)
    except Exception as e:
        # ì˜ˆ: ì±„íŒ… ì¢…ë£Œ ì „ì—ëŠ” í‰ê°€ ë¶ˆê°€ ë“±ì˜ ì˜ˆì™¸ ë°œìƒ ê°€ëŠ¥, ë¬´ì‹œí•˜ê³  ì§„í–‰
        pass
    msgs = db.query(models.ChatMessage).filter_by(history_id=chat_history.id).order_by(models.ChatMessage.id.asc()).all()
    items = []
    qid = 1
    for i in range(0,len(msgs)-1,2):
        if msgs[i].role=="user" and msgs[i+1].role=="ai":
            d = json.loads(msgs[i+1].text)
            
            # ê¸°ì¡´ ë°ì´í„°ì˜ recommendations í•„ë“œë„ ì •ë¦¬
            recommendations = d.get("recommendations", [])
            if isinstance(recommendations, dict):
                recommendations = list(recommendations.values())
            elif isinstance(recommendations, list):
                # ì¤‘ì²©ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ í‰í‰í•˜ê²Œ ë§Œë“¤ê¸°
                flattened_recommendations = []
                for item in recommendations:
                    if isinstance(item, list):
                        flattened_recommendations.extend(item)
                    elif isinstance(item, str):
                        flattened_recommendations.append(item)
                recommendations = flattened_recommendations
            else:
                recommendations = []
            
            d["recommendations"] = recommendations
            
            items.append(ChatItemModel(
                question_id=qid,
                question=msgs[i].text,
                answer=d.get("description",""),
                chat_res=ChatResModel.model_validate(d)
            ))
            qid += 1
    return {"history_id": chat_history.id, "items": items}

@router.post("/end/{history_id}")
async def end_chat_session(
    history_id: int,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    chat = db.query(models.ChatHistory).filter_by(id=history_id, user_id=current_user.id).first()
    if not chat:
        raise HTTPException(status_code=404, detail="ëŒ€í™” ì„¸ì…˜ ì—†ìŒ")
    if chat.ended_at:
        return {"message": "ì´ë¯¸ ì¢…ë£Œë¨", "ended_at": chat.ended_at}
    
    # ëŒ€í™” ì¢…ë£Œ ì‹œê°„ ì„¤ì •
    chat.ended_at = datetime.now(timezone.utc)
    db.commit()
    
    # ì±—ë´‡ ëŒ€í™” ë¶„ì„ ê²°ê³¼ë¥¼ SurveyResultë¡œ ì €ì¥
    try:
        survey_result = await save_chatbot_analysis_result(
            user_id=current_user.id,
            chat_history_id=history_id,
            db=db
        )
        
        if survey_result:
            return {
                "message": "ëŒ€í™” ì¢…ë£Œ ë° ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ", 
                "ended_at": chat.ended_at,
                "survey_result_id": survey_result.id,
                "personal_color_type": survey_result.result_tone
            }
        else:
            return {
                "message": "ëŒ€í™” ì¢…ë£Œë¨ (ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨)", 
                "ended_at": chat.ended_at
            }
            
    except Exception as e:
        print(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "message": "ëŒ€í™” ì¢…ë£Œë¨ (ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ)", 
            "ended_at": chat.ended_at
        }

@router.post("/analyze/{history_id}")
async def analyze_chat_for_personal_color(
    history_id: int,
    current_user: models.User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    íŠ¹ì • ì±„íŒ… ì„¸ì…˜ì„ ë¶„ì„í•˜ì—¬ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨ ê²°ê³¼ë¥¼ ì¦‰ì‹œ ìƒì„±
    (ëŒ€í™” ì¢…ë£Œì™€ ë³„ê°œë¡œ ë¶„ì„ ê²°ê³¼ë§Œ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©)
    """
    chat = db.query(models.ChatHistory).filter_by(id=history_id, user_id=current_user.id).first()
    if not chat:
        raise HTTPException(status_code=404, detail="ëŒ€í™” ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        survey_result = await save_chatbot_analysis_result(
            user_id=current_user.id,
            chat_history_id=history_id,
            db=db
        )
        
        if survey_result:
            # JSON í•„ë“œë“¤ì„ íŒŒì‹±í•˜ì—¬ ë°˜í™˜
            return {
                "message": "ë¶„ì„ ì™„ë£Œ",
                "survey_result_id": survey_result.id,
                "result_tone": survey_result.result_tone,
                "result_name": survey_result.result_name,
                "confidence": survey_result.confidence,
                "detailed_analysis": survey_result.detailed_analysis,
                "color_palette": json.loads(survey_result.color_palette) if survey_result.color_palette else [],
                "style_keywords": json.loads(survey_result.style_keywords) if survey_result.style_keywords else [],
                "makeup_tips": json.loads(survey_result.makeup_tips) if survey_result.makeup_tips else [],
                "top_types": json.loads(survey_result.top_types) if survey_result.top_types else []
            }
        else:
            raise HTTPException(status_code=400, detail="ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
